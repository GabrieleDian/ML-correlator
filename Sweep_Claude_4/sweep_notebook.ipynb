{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Hyperparameter Optimization with WandB Sweeps\n",
    "\n",
    "This notebook demonstrates how to use WandB sweeps for hyperparameter optimization of GNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import wandb\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "from GraphBuilder_with_features import create_graph_dataset\n",
    "from sweep_utils import (\n",
    "    run_sweep, \n",
    "    quick_sweep,\n",
    "    analyze_sweep_results,\n",
    "    create_example_config_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data function\n",
    "def load_graph_data(loop):\n",
    "    \"\"\"Load graph data from CSV files.\"\"\"\n",
    "    edges = []\n",
    "    y = []\n",
    "    \n",
    "    filename = f'../Graph_Edge_Data/den_graph_data_{loop}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    edges += df['EDGES'].tolist()\n",
    "    y += df['COEFFICIENTS'].tolist()\n",
    "    \n",
    "    edges = [ast.literal_eval(e) for e in edges]\n",
    "    graphs_data = list(zip(edges, y))\n",
    "    return graphs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "graphs_data = load_graph_data(loop=8)\n",
    "print(f\"Loaded {len(graphs_data)} graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with chosen features\n",
    "feature_config = {\n",
    "    'selected_features': ['basic', 'face', 'spectral_node', 'centrality'],\n",
    "    'laplacian_pe_k': 3\n",
    "}\n",
    "\n",
    "dataset, scaler = create_graph_dataset(graphs_data, feature_config)\n",
    "print(f\"Dataset created with {len(dataset)} graphs\")\n",
    "print(f\"Feature dimensions: {dataset[0].x.shape[1]}\")\n",
    "print(f\"Feature names: {dataset[0].feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter ranges for grid search\n",
    "param_ranges = {\n",
    "    'hidden_channels': [32, 64, 128],\n",
    "    'num_layers': [2, 3, 4],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'lr': [0.001, 0.003, 0.01],\n",
    "    'weight_decay': [0, 1e-4, 5e-4]\n",
    "}\n",
    "\n",
    "# Calculate total number of combinations\n",
    "total_runs = 1\n",
    "for param, values in param_ranges.items():\n",
    "    total_runs *= len(values)\n",
    "    print(f\"{param}: {len(values)} values - {values}\")\n",
    "\n",
    "print(f\"\\nTotal combinations: {total_runs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed configuration (not swept)\n",
    "fixed_config = {\n",
    "    'model_name': 'gin',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 32,\n",
    "    'scheduler_type': 'onecycle',\n",
    "    'save_models': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Hyperparameter Sweep\n",
    "\n",
    "### Option A: Quick Test (Fewer Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with fewer combinations\n",
    "quick_param_ranges = {\n",
    "    'hidden_channels': [32, 64],\n",
    "    'num_layers': [2, 3],\n",
    "    'dropout': [0.1, 0.2],\n",
    "    'lr': [0.001, 0.01],\n",
    "    'weight_decay': [0, 1e-4]\n",
    "}\n",
    "\n",
    "# Calculate combinations\n",
    "quick_runs = 1\n",
    "for values in quick_param_ranges.values():\n",
    "    quick_runs *= len(values)\n",
    "print(f\"Quick test combinations: {quick_runs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run quick sweep\n",
    "project_name = \"gnn-planar-graphs-sweep\"\n",
    "sweep_name = \"quick_test\"\n",
    "\n",
    "# Uncomment to run:\n",
    "# sweep_id = run_sweep(\n",
    "#     param_ranges=quick_param_ranges,\n",
    "#     dataset=dataset,\n",
    "#     project_name=project_name,\n",
    "#     fixed_config=fixed_config,\n",
    "#     sweep_name=sweep_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Full Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full sweep - WARNING: This will run many experiments!\n",
    "# sweep_id = run_sweep(\n",
    "#     param_ranges=param_ranges,\n",
    "#     dataset=dataset,\n",
    "#     project_name=project_name,\n",
    "#     fixed_config=fixed_config,\n",
    "#     sweep_name=\"full_grid_search\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Using the Quick Sweep Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even quicker sweep with default parameters\n",
    "# sweep_id = quick_sweep(\n",
    "#     dataset=dataset,\n",
    "#     project_name=project_name,\n",
    "#     hidden_channels=[32, 64],\n",
    "#     num_layers=[2, 3],\n",
    "#     dropout=[0.15, 0.25],\n",
    "#     lr=[0.001, 0.005],\n",
    "#     weight_decay=[0, 1e-4],\n",
    "#     epochs=50  # Fewer epochs for testing\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Sweep Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual sweep ID\n",
    "# sweep_id = \"your-sweep-id-here\"\n",
    "# results = analyze_sweep_results(project_name, sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best configuration\n",
    "# if results['best_config']:\n",
    "#     print(\"Best Configuration Found:\")\n",
    "#     print(f\"Validation Accuracy: {results['best_config']['best_val_accuracy']:.4f}\")\n",
    "#     print(\"\\nHyperparameters:\")\n",
    "#     for param, value in results['best_config']['config'].items():\n",
    "#         if param in param_ranges:\n",
    "#             print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top N configurations\n",
    "# N = 10\n",
    "# print(f\"\\nTop {N} Configurations:\")\n",
    "# for i, config in enumerate(results['all_results'][:N]):\n",
    "#     print(f\"\\n{i+1}. Validation Accuracy: {config['best_val_accuracy']:.4f}\")\n",
    "#     print(\"   Config:\", {k: v for k, v in config['config'].items() if k in param_ranges})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize hyperparameter importance\n",
    "def plot_hyperparameter_importance(results, param_name):\n",
    "    \"\"\"Plot validation accuracy distribution for different values of a hyperparameter.\"\"\"\n",
    "    if not results['all_results']:\n",
    "        print(\"No results to plot\")\n",
    "        return\n",
    "    \n",
    "    # Extract data\n",
    "    param_values = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for run in results['all_results']:\n",
    "        if param_name in run['config']:\n",
    "            param_values.append(run['config'][param_name])\n",
    "            accuracies.append(run['best_val_accuracy'])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        param_name: param_values,\n",
    "        'validation_accuracy': accuracies\n",
    "    })\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=param_name, y='validation_accuracy', data=df)\n",
    "    plt.title(f'Validation Accuracy vs {param_name}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for each hyperparameter\n",
    "# for param in param_ranges.keys():\n",
    "#     plot_hyperparameter_importance(results, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap for two hyperparameters\n",
    "def plot_2d_heatmap(results, param1, param2):\n",
    "    \"\"\"Create a heatmap showing validation accuracy for two hyperparameters.\"\"\"\n",
    "    if not results['all_results']:\n",
    "        print(\"No results to plot\")\n",
    "        return\n",
    "    \n",
    "    # Extract data\n",
    "    data = {}\n",
    "    for run in results['all_results']:\n",
    "        if param1 in run['config'] and param2 in run['config']:\n",
    "            key = (run['config'][param1], run['config'][param2])\n",
    "            if key not in data or run['best_val_accuracy'] > data[key]:\n",
    "                data[key] = run['best_val_accuracy']\n",
    "    \n",
    "    # Create matrix\n",
    "    param1_values = sorted(set(k[0] for k in data.keys()))\n",
    "    param2_values = sorted(set(k[1] for k in data.keys()))\n",
    "    \n",
    "    matrix = np.zeros((len(param2_values), len(param1_values)))\n",
    "    for i, p2 in enumerate(param2_values):\n",
    "        for j, p1 in enumerate(param1_values):\n",
    "            matrix[i, j] = data.get((p1, p2), 0)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, \n",
    "                xticklabels=param1_values, \n",
    "                yticklabels=param2_values,\n",
    "                annot=True, \n",
    "                fmt='.3f', \n",
    "                cmap='viridis')\n",
    "    plt.xlabel(param1)\n",
    "    plt.ylabel(param2)\n",
    "    plt.title(f'Validation Accuracy: {param1} vs {param2}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmaps for interesting parameter pairs\n",
    "# plot_2d_heatmap(results, 'hidden_channels', 'num_layers')\n",
    "# plot_2d_heatmap(results, 'lr', 'weight_decay')\n",
    "# plot_2d_heatmap(results, 'hidden_channels', 'dropout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "# import json\n",
    "# with open(f'sweep_results_{sweep_id}.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=2)\n",
    "# print(f\"Results saved to sweep_results_{sweep_id}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFrame\n",
    "# if results['all_results']:\n",
    "#     summary_data = []\n",
    "#     for run in results['all_results']:\n",
    "#         row = {\n",
    "#             'val_accuracy': run['best_val_accuracy'],\n",
    "#             'train_accuracy': run['final_train_accuracy'],\n",
    "#             'best_epoch': run['best_epoch']\n",
    "#         }\n",
    "#         # Add hyperparameters\n",
    "#         for param in param_ranges.keys():\n",
    "#             if param in run['config']:\n",
    "#                 row[param] = run['config'][param]\n",
    "#         summary_data.append(row)\n",
    "#     \n",
    "#     summary_df = pd.DataFrame(summary_data)\n",
    "#     summary_df.to_csv(f'sweep_summary_{sweep_id}.csv', index=False)\n",
    "#     print(\"Summary saved to CSV\")\n",
    "#     print(summary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Final Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameters\n",
    "# if results['best_config']:\n",
    "#     best_params = results['best_config']['config']\n",
    "#     \n",
    "#     # Create configuration for final training\n",
    "#     final_config = SimpleNamespace(\n",
    "#         model_name='gin',\n",
    "#         hidden_channels=best_params['hidden_channels'],\n",
    "#         num_layers=best_params['num_layers'],\n",
    "#         dropout=best_params['dropout'],\n",
    "#         lr=best_params['lr'],\n",
    "#         weight_decay=best_params['weight_decay'],\n",
    "#         epochs=150,  # Train longer for final model\n",
    "#         batch_size=32,\n",
    "#         scheduler_type='onecycle',\n",
    "#         use_wandb=True,\n",
    "#         project='gnn-planar-graphs-final',\n",
    "#         experiment_name='best_model_from_sweep',\n",
    "#         in_channels=dataset[0].x.shape[1]\n",
    "#     )\n",
    "#     \n",
    "#     # Train final model\n",
    "#     from training_utils import train\n",
    "#     final_results = train(final_config, dataset)\n",
    "#     \n",
    "#     print(f\"Final model validation accuracy: {final_results['best_val_acc']:.4f}\")\n",
    "#     \n",
    "#     # Save the final model\n",
    "#     torch.save(final_results['model_state'], 'best_model_from_sweep.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
