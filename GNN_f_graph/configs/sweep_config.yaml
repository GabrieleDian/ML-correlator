# Simple WandB Sweep Configuration
# Good starting point for hyperparameter search
project: "f_graph_gnn_loopto9graphlet"
program: one_run_simple_f.py
method: random  # Random search is simple and effective
metric:
  name: train_recall
  goal: maximize

parameters:
  # Base config file
  config:
    value: configs/config.yaml
  # Learning rate
  learning_rate:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.005
  # Weight decay (L2 regularization)
  weight_decay:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.0005
  # Hidden layer size
  hidden_channels:
    values: [128, 256, 512]
  # Dropout rate
  dropout:
    values: [0.3, 0.4, 0.5]
  # Batch size
  batch_size:
    values: [128, 256, 512]
  
run_cap: 20