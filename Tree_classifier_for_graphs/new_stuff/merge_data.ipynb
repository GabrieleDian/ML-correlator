{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source directories:\n",
      "den_graphs: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/den_graphs\n",
      "motif_features: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/motif_features_den\n",
      "output: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged\n",
      "\n",
      "Files in den_graphs: ['6loopfeats_enhanced.csv', '8loopfeats_enhanced.csv', '11loopfeats_enhanced.csv', '5loopfeats_enhanced.csv', '7loopfeats_enhanced.csv', '9loopfeats_enhanced.csv', '10loopfeats_enhanced.csv']\n",
      "Files in motif_features: ['9loops.csv', '8loops.csv', '11loops.csv', '10loops.csv', '9loops_manifest.json', '5loops.csv', '7loops_manifest.json', '6loops_manifest.json', '8loops_manifest.json', '5loops_manifest.json', '10loops_manifest.json', '7loops.csv', '6loops.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the source directories\n",
    "den_graphs_dir = \"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/den_graphs\"\n",
    "motif_features_dir = \"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/motif_features_den\"\n",
    "output_dir = \"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged\"\n",
    "\n",
    "print(\"Source directories:\")\n",
    "print(f\"den_graphs: {den_graphs_dir}\")\n",
    "print(f\"motif_features: {motif_features_dir}\")  \n",
    "print(f\"output: {output_dir}\")\n",
    "\n",
    "# List files in both directories\n",
    "den_files = os.listdir(den_graphs_dir)\n",
    "motif_files = os.listdir(motif_features_dir)\n",
    "\n",
    "print(f\"\\nFiles in den_graphs: {den_files}\")\n",
    "print(f\"Files in motif_features: {motif_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mapping:\n",
      "den_graphs files: {6: '6loopfeats_enhanced.csv', 8: '8loopfeats_enhanced.csv', 11: '11loopfeats_enhanced.csv', 5: '5loopfeats_enhanced.csv', 7: '7loopfeats_enhanced.csv', 9: '9loopfeats_enhanced.csv', 10: '10loopfeats_enhanced.csv'}\n",
      "motif_features files: {9: '9loops.csv', 8: '8loops.csv', 11: '11loops.csv', 10: '10loops.csv', 5: '5loops.csv', 7: '7loops.csv', 6: '6loops.csv'}\n",
      "\n",
      "Common loop numbers to process: [5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "# Analyze file naming patterns and identify matching files\n",
    "def extract_loop_number(filename):\n",
    "    \"\"\"Extract loop number from filename\"\"\"\n",
    "    if '5loop' in filename:\n",
    "        return 5\n",
    "    elif '6loop' in filename:\n",
    "        return 6\n",
    "    elif '7loop' in filename:\n",
    "        return 7\n",
    "    elif '8loop' in filename:\n",
    "        return 8\n",
    "    elif '9loop' in filename:\n",
    "        return 9\n",
    "    elif '10loop' in filename:\n",
    "        return 10\n",
    "    elif '11loop' in filename:\n",
    "        return 11\n",
    "    return None\n",
    "\n",
    "# Create mapping of loop numbers to files\n",
    "den_file_map = {}\n",
    "motif_file_map = {}\n",
    "\n",
    "for file in den_files:\n",
    "    if file.endswith('.csv'):\n",
    "        loop_num = extract_loop_number(file)\n",
    "        if loop_num:\n",
    "            den_file_map[loop_num] = file\n",
    "\n",
    "for file in motif_files:\n",
    "    if file.endswith('.csv'):\n",
    "        loop_num = extract_loop_number(file)\n",
    "        if loop_num:\n",
    "            motif_file_map[loop_num] = file\n",
    "\n",
    "print(\"File mapping:\")\n",
    "print(f\"den_graphs files: {den_file_map}\")\n",
    "print(f\"motif_features files: {motif_file_map}\")\n",
    "\n",
    "# Find common loop numbers\n",
    "common_loops = set(den_file_map.keys()) & set(motif_file_map.keys())\n",
    "print(f\"\\nCommon loop numbers to process: {sorted(common_loops)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCANNING ALL FILES TO DETERMINE COMPLETE COLUMN STRUCTURE\n",
      "============================================================\n",
      "\n",
      "Den graphs columns:\n",
      "  Columns in ALL files: 178\n",
      "  Total unique columns (union): 179\n",
      "  Columns missing in some files: 1\n",
      "\n",
      "Motif features columns:\n",
      "  Columns in ALL files: 101\n",
      "  Total unique columns (union): 101\n",
      "  Columns missing in some files: 0\n",
      "\n",
      "Per-file column count:\n",
      "  Loop 5: den=178 cols, motif=101 cols\n",
      "  Loop 6: den=178 cols, motif=101 cols\n",
      "  Loop 7: den=179 cols, motif=101 cols\n",
      "  Loop 8: den=179 cols, motif=101 cols\n",
      "  Loop 9: den=179 cols, motif=101 cols\n",
      "  Loop 10: den=179 cols, motif=101 cols\n",
      "  Loop 11: den=179 cols, motif=101 cols\n",
      "\n",
      "Testing merge with loop 5:\n",
      "\n",
      "Processing: 5loopfeats_enhanced.csv + 5loops.csv\n",
      "den_graphs shape: (7, 178)\n",
      "motif_features shape: (7, 101)\n",
      "Adding 1 missing columns to den_graphs (filled with NaN)\n",
      "After ensuring complete columns - den_graphs shape: (7, 179)\n",
      "After ensuring complete columns - motif_features shape: (7, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (7, 66)\n",
      "Concatenated shape: (7, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/5loops_merged.csv\n",
      "Test merge successful! Total columns: 245\n"
     ]
    }
   ],
   "source": [
    "# First, scan all files to determine the complete set of columns to ensure consistency\n",
    "def determine_column_sets(den_graphs_dir, motif_features_dir, den_file_map, motif_file_map, common_loops):\n",
    "    \"\"\"\n",
    "    Scan all files to determine the complete set of columns that should be in all merged files.\n",
    "    Returns the union of all columns from all files (keeps all columns, even with nulls).\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SCANNING ALL FILES TO DETERMINE COMPLETE COLUMN STRUCTURE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_den_columns = {}\n",
    "    all_motif_columns = {}\n",
    "    \n",
    "    # Collect all columns from all files\n",
    "    for loop_num in sorted(common_loops):\n",
    "        den_file = os.path.join(den_graphs_dir, den_file_map[loop_num])\n",
    "        motif_file = os.path.join(motif_features_dir, motif_file_map[loop_num])\n",
    "        \n",
    "        den_df = pd.read_csv(den_file)\n",
    "        motif_df = pd.read_csv(motif_file)\n",
    "        \n",
    "        all_den_columns[loop_num] = set(den_df.columns)\n",
    "        all_motif_columns[loop_num] = set(motif_df.columns)\n",
    "    \n",
    "    # Get union of all columns (columns that appear in ANY file)\n",
    "    den_cols_union = set.union(*all_den_columns.values())\n",
    "    motif_cols_union = set.union(*all_motif_columns.values())\n",
    "    \n",
    "    # Get intersection (columns that appear in ALL files)\n",
    "    den_cols_intersection = set.intersection(*all_den_columns.values())\n",
    "    motif_cols_intersection = set.intersection(*all_motif_columns.values())\n",
    "    \n",
    "    print(f\"\\nDen graphs columns:\")\n",
    "    print(f\"  Columns in ALL files: {len(den_cols_intersection)}\")\n",
    "    print(f\"  Total unique columns (union): {len(den_cols_union)}\")\n",
    "    print(f\"  Columns missing in some files: {len(den_cols_union - den_cols_intersection)}\")\n",
    "    \n",
    "    print(f\"\\nMotif features columns:\")\n",
    "    print(f\"  Columns in ALL files: {len(motif_cols_intersection)}\")\n",
    "    print(f\"  Total unique columns (union): {len(motif_cols_union)}\")\n",
    "    print(f\"  Columns missing in some files: {len(motif_cols_union - motif_cols_intersection)}\")\n",
    "    \n",
    "    # Report which files have which columns\n",
    "    print(\"\\nPer-file column count:\")\n",
    "    for loop_num in sorted(common_loops):\n",
    "        print(f\"  Loop {loop_num}: den={len(all_den_columns[loop_num])} cols, motif={len(all_motif_columns[loop_num])} cols\")\n",
    "    \n",
    "    return den_cols_union, motif_cols_union, all_den_columns, all_motif_columns\n",
    "\n",
    "# Function to concatenate CSV files and ensure consistent column structure\n",
    "def merge_csv_files(den_file_path, motif_file_path, output_path, den_cols_union=None, motif_cols_union=None):\n",
    "    \"\"\"\n",
    "    Concatenate two CSV files and ensure all output files have identical column structure.\n",
    "    Missing columns are added with NaN values to ensure consistency.\n",
    "    \n",
    "    Args:\n",
    "        den_file_path: Path to den_graphs CSV file\n",
    "        motif_file_path: Path to motif_features CSV file\n",
    "        output_path: Path to save merged CSV file\n",
    "        den_cols_union: Set of all columns that should be in den_graphs (from all files)\n",
    "        motif_cols_union: Set of all columns that should be in motif_features (from all files)\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing: {os.path.basename(den_file_path)} + {os.path.basename(motif_file_path)}\")\n",
    "    \n",
    "    # Read the CSV files\n",
    "    den_df = pd.read_csv(den_file_path)\n",
    "    motif_df = pd.read_csv(motif_file_path)\n",
    "    \n",
    "    print(f\"den_graphs shape: {den_df.shape}\")\n",
    "    print(f\"motif_features shape: {motif_df.shape}\")\n",
    "    \n",
    "    # Ensure all files have the same columns in the same order\n",
    "    if den_cols_union is not None:\n",
    "        missing_den_cols = den_cols_union - set(den_df.columns)\n",
    "        if missing_den_cols:\n",
    "            print(f\"Adding {len(missing_den_cols)} missing columns to den_graphs (filled with NaN)\")\n",
    "            for col in missing_den_cols:\n",
    "                den_df[col] = np.nan\n",
    "        # Reorder to match sorted union for consistency\n",
    "        den_df = den_df[sorted(den_cols_union)]\n",
    "    \n",
    "    # Ensure all files have the same columns in the same order\n",
    "    if motif_cols_union is not None:\n",
    "        missing_motif_cols = motif_cols_union - set(motif_df.columns)\n",
    "        if missing_motif_cols:\n",
    "            print(f\"Adding {len(missing_motif_cols)} missing columns to motif_features (filled with NaN)\")\n",
    "            for col in missing_motif_cols:\n",
    "                motif_df[col] = np.nan\n",
    "        # Reorder to match sorted union for consistency\n",
    "        motif_df = motif_df[sorted(motif_cols_union)]\n",
    "    \n",
    "    print(f\"After ensuring complete columns - den_graphs shape: {den_df.shape}\")\n",
    "    print(f\"After ensuring complete columns - motif_features shape: {motif_df.shape}\")\n",
    "    \n",
    "    # Find common columns\n",
    "    common_cols = set(den_df.columns) & set(motif_df.columns)\n",
    "    print(f\"Common columns: {len(common_cols)}\")\n",
    "    \n",
    "    # Remove duplicated columns from motif_df (keep den_df version)\n",
    "    motif_df_unique = motif_df.drop(columns=list(common_cols))\n",
    "    print(f\"After removing duplicated columns - motif_features shape: {motif_df_unique.shape}\")\n",
    "    \n",
    "    # Concatenate the dataframes\n",
    "    merged_df = pd.concat([den_df, motif_df_unique], axis=1)\n",
    "    \n",
    "    print(f\"Concatenated shape: {merged_df.shape}\")\n",
    "    print(f\"Total columns: {len(merged_df.columns)}\")\n",
    "    \n",
    "    # Save the merged file\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved merged file to: {output_path}\")\n",
    "    \n",
    "    return merged_df.columns.tolist()  # Return column list for verification\n",
    "\n",
    "# First, determine the complete set of columns from all files\n",
    "den_cols_union, motif_cols_union, all_den_columns, all_motif_columns = determine_column_sets(\n",
    "    den_graphs_dir, motif_features_dir, den_file_map, motif_file_map, common_loops\n",
    ")\n",
    "\n",
    "# Test with one file pair first\n",
    "if common_loops:\n",
    "    test_loop = min(common_loops)\n",
    "    den_file = os.path.join(den_graphs_dir, den_file_map[test_loop])\n",
    "    motif_file = os.path.join(motif_features_dir, motif_file_map[test_loop])\n",
    "    output_file = os.path.join(output_dir, f\"{test_loop}loops_merged.csv\")\n",
    "    \n",
    "    print(f\"\\nTesting merge with loop {test_loop}:\")\n",
    "    test_columns = merge_csv_files(den_file, motif_file, output_file, den_cols_union, motif_cols_union)\n",
    "    \n",
    "    if test_columns:\n",
    "        print(f\"Test merge successful! Total columns: {len(test_columns)}\")\n",
    "    else:\n",
    "        print(\"Test merge failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/5loops_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROCESSING ALL LOOP FILES\n",
      "============================================================\n",
      "\n",
      "========================================\n",
      "Processing 5-loop files\n",
      "========================================\n",
      "\n",
      "Processing: 5loopfeats_enhanced.csv + 5loops.csv\n",
      "den_graphs shape: (7, 178)\n",
      "motif_features shape: (7, 101)\n",
      "Adding 1 missing columns to den_graphs (filled with NaN)\n",
      "After ensuring complete columns - den_graphs shape: (7, 179)\n",
      "After ensuring complete columns - motif_features shape: (7, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (7, 66)\n",
      "Concatenated shape: (7, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/5loops_merged.csv\n",
      "✅ Successfully merged 5-loop files (245 columns)\n",
      "\n",
      "========================================\n",
      "Processing 6-loop files\n",
      "========================================\n",
      "\n",
      "Processing: 6loopfeats_enhanced.csv + 6loops.csv\n",
      "den_graphs shape: (31, 178)\n",
      "motif_features shape: (31, 101)\n",
      "Adding 1 missing columns to den_graphs (filled with NaN)\n",
      "After ensuring complete columns - den_graphs shape: (31, 179)\n",
      "After ensuring complete columns - motif_features shape: (31, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (31, 66)\n",
      "Concatenated shape: (31, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/6loops_merged.csv\n",
      "✅ Successfully merged 6-loop files (245 columns)\n",
      "\n",
      "========================================\n",
      "Processing 7-loop files\n",
      "========================================\n",
      "\n",
      "Processing: 7loopfeats_enhanced.csv + 7loops.csv\n",
      "den_graphs shape: (164, 179)\n",
      "motif_features shape: (164, 101)\n",
      "After ensuring complete columns - den_graphs shape: (164, 179)\n",
      "After ensuring complete columns - motif_features shape: (164, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (164, 66)\n",
      "Concatenated shape: (164, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/7loops_merged.csv\n",
      "✅ Successfully merged 7-loop files (245 columns)\n",
      "\n",
      "========================================\n",
      "Processing 8-loop files\n",
      "========================================\n",
      "\n",
      "Processing: 8loopfeats_enhanced.csv + 8loops.csv\n",
      "den_graphs shape: (1432, 179)\n",
      "motif_features shape: (1432, 101)\n",
      "After ensuring complete columns - den_graphs shape: (1432, 179)\n",
      "After ensuring complete columns - motif_features shape: (1432, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (1432, 66)\n",
      "Concatenated shape: (1432, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/8loops_merged.csv\n",
      "✅ Successfully merged 8-loop files (245 columns)\n",
      "\n",
      "========================================\n",
      "Processing 9-loop files\n",
      "========================================\n",
      "\n",
      "Processing: 9loopfeats_enhanced.csv + 9loops.csv\n",
      "den_graphs shape: (13972, 179)\n",
      "motif_features shape: (13972, 101)\n",
      "After ensuring complete columns - den_graphs shape: (13972, 179)\n",
      "After ensuring complete columns - motif_features shape: (13972, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (13972, 66)\n",
      "Concatenated shape: (13972, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/9loops_merged.csv\n",
      "✅ Successfully merged 9-loop files (245 columns)\n",
      "\n",
      "========================================\n",
      "Processing 10-loop files\n",
      "========================================\n",
      "\n",
      "Processing: 10loopfeats_enhanced.csv + 10loops.csv\n",
      "den_graphs shape: (153252, 179)\n",
      "motif_features shape: (153252, 101)\n",
      "After ensuring complete columns - den_graphs shape: (153252, 179)\n",
      "After ensuring complete columns - motif_features shape: (153252, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (153252, 66)\n",
      "Concatenated shape: (153252, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/10loops_merged.csv\n",
      "✅ Successfully merged 10-loop files (245 columns)\n",
      "\n",
      "========================================\n",
      "Processing 11-loop files\n",
      "========================================\n",
      "\n",
      "Processing: 11loopfeats_enhanced.csv + 11loops.csv\n",
      "den_graphs shape: (1697302, 179)\n",
      "motif_features shape: (1697302, 101)\n",
      "After ensuring complete columns - den_graphs shape: (1697302, 179)\n",
      "After ensuring complete columns - motif_features shape: (1697302, 101)\n",
      "Common columns: 35\n",
      "After removing duplicated columns - motif_features shape: (1697302, 66)\n",
      "Concatenated shape: (1697302, 245)\n",
      "Total columns: 245\n",
      "Saved merged file to: /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged/11loops_merged.csv\n",
      "✅ Successfully merged 11-loop files (245 columns)\n",
      "\n",
      "============================================================\n",
      "COLUMN CONSISTENCY VERIFICATION\n",
      "============================================================\n",
      "Columns present in ALL files: 245\n",
      "Total unique columns across all files: 245\n",
      "\n",
      "✅ All files have identical column structures!\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Successfully merged: [5, 6, 7, 8, 9, 10, 11]\n",
      "Failed merges: []\n",
      "Total processed: 7\n",
      "Success rate: 7/7 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Process all loop files and merge them\n",
    "print(\"=\" * 60)\n",
    "print(\"PROCESSING ALL LOOP FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "successful_merges = []\n",
    "failed_merges = []\n",
    "all_merged_columns = {}  # Track columns in each merged file\n",
    "\n",
    "for loop_num in sorted(common_loops):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Processing {loop_num}-loop files\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    den_file = os.path.join(den_graphs_dir, den_file_map[loop_num])\n",
    "    motif_file = os.path.join(motif_features_dir, motif_file_map[loop_num])\n",
    "    output_file = os.path.join(output_dir, f\"{loop_num}loops_merged.csv\")\n",
    "    \n",
    "    try:\n",
    "        merged_columns = merge_csv_files(den_file, motif_file, output_file, den_cols_union, motif_cols_union)\n",
    "        if merged_columns:\n",
    "            successful_merges.append(loop_num)\n",
    "            all_merged_columns[loop_num] = set(merged_columns)\n",
    "            print(f\"✅ Successfully merged {loop_num}-loop files ({len(merged_columns)} columns)\")\n",
    "        else:\n",
    "            failed_merges.append(loop_num)\n",
    "            print(f\"❌ Failed to merge {loop_num}-loop files\")\n",
    "    except Exception as e:\n",
    "        failed_merges.append(loop_num)\n",
    "        print(f\"❌ Error processing {loop_num}-loop files: {str(e)}\")\n",
    "\n",
    "# Verify column consistency\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COLUMN CONSISTENCY VERIFICATION\")\n",
    "print(f\"{'='*60}\")\n",
    "if all_merged_columns:\n",
    "    # Get union of all columns\n",
    "    all_cols_union = set.union(*all_merged_columns.values())\n",
    "    # Get intersection of all columns (columns present in all files)\n",
    "    all_cols_intersection = set.intersection(*all_merged_columns.values())\n",
    "    \n",
    "    print(f\"Columns present in ALL files: {len(all_cols_intersection)}\")\n",
    "    print(f\"Total unique columns across all files: {len(all_cols_union)}\")\n",
    "    \n",
    "    # Check for columns missing in some files\n",
    "    inconsistent_cols = {}\n",
    "    for loop_num, cols in all_merged_columns.items():\n",
    "        missing = all_cols_union - cols\n",
    "        if missing:\n",
    "            inconsistent_cols[loop_num] = missing\n",
    "    \n",
    "    if inconsistent_cols:\n",
    "        print(f\"\\n⚠️  WARNING: Found inconsistent columns across files:\")\n",
    "        for loop_num, missing_cols in inconsistent_cols.items():\n",
    "            print(f\"  {loop_num}-loop file missing {len(missing_cols)} columns: {sorted(list(missing_cols))[:5]}\")\n",
    "            if len(missing_cols) > 5:\n",
    "                print(f\"    ... and {len(missing_cols) - 5} more\")\n",
    "    else:\n",
    "        print(\"\\n✅ All files have identical column structures!\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Successfully merged: {successful_merges}\")\n",
    "print(f\"Failed merges: {failed_merges}\")\n",
    "print(f\"Total processed: {len(common_loops)}\")\n",
    "print(f\"Success rate: {len(successful_merges)}/{len(common_loops)} ({len(successful_merges)/len(common_loops)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "Files created in /Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/new2_merged:\n",
      "  - 10loops_merged.csv (445,720,585 bytes)\n",
      "  - 11loops_merged.csv (4,936,597,498 bytes)\n",
      "  - 5loops_merged.csv (23,910 bytes)\n",
      "  - 6loops_merged.csv (85,329 bytes)\n",
      "  - 7loops_merged.csv (446,806 bytes)\n",
      "  - 8loops_merged.csv (4,037,792 bytes)\n",
      "  - 9loops_merged.csv (40,296,068 bytes)\n",
      "\n",
      "Total merged files created: 7\n",
      "\n",
      "Sample of 5loops_merged.csv:\n",
      "Shape: (7, 245)\n",
      "Columns: 245\n",
      "First few column names: ['Adjacency_energy', 'Adjacency_energy_over_fro', 'Adjacency_energy_per_node', 'Adjacency_estrada_index', 'Adjacency_estrada_per_node', 'Adjacency_moment_2', 'Adjacency_moment_2_over_avgdeg', 'Adjacency_moment_3', 'Adjacency_moment_3_over_avgdeg3', 'Adjacency_moment_4']\n",
      "First few rows:\n",
      "   Adjacency_energy  Adjacency_energy_over_fro  Adjacency_energy_per_node  \\\n",
      "0         17.059978                   2.632412                   1.895553   \n",
      "1         16.864605                   2.666528                   1.873845   \n",
      "\n",
      "   Adjacency_estrada_index  Adjacency_estrada_per_node  Adjacency_moment_2  \\\n",
      "0               122.003142                   13.555905            4.666667   \n",
      "1               101.693620                   11.299291            4.444444   \n",
      "\n",
      "   Adjacency_moment_2_over_avgdeg  Adjacency_moment_3  \\\n",
      "0                             1.0            9.333333   \n",
      "1                             1.0            8.000000   \n",
      "\n",
      "   Adjacency_moment_3_over_avgdeg3  Adjacency_moment_4  ...  \\\n",
      "0                         0.091837           60.666667  ...   \n",
      "1                         0.091125           51.555556  ...   \n",
      "\n",
      "   Motif_induced_g_6_4  Motif_induced_g_6_4_per_Cn4  \\\n",
      "0                  0.0                          0.0   \n",
      "1                  0.0                          0.0   \n",
      "\n",
      "   Spectral_adjacency_energy  Spectral_adjacency_estrada_index  \\\n",
      "0                  17.059978                        122.003142   \n",
      "1                  16.864605                        101.693620   \n",
      "\n",
      "   Spectral_adjacency_moment_2  Spectral_adjacency_moment_3  \\\n",
      "0                     4.666667                     9.333333   \n",
      "1                     4.444444                     8.000000   \n",
      "\n",
      "   Spectral_adjacency_moment_4  Spectral_kirchhoff_index  \\\n",
      "0                    60.666667                 15.321429   \n",
      "1                    51.555556                 16.285714   \n",
      "\n",
      "   Spectral_laplacian_heat_trace_t0.5  Spectral_laplacian_heat_trace_t2.0  \n",
      "0                            1.791352                            1.005313  \n",
      "1                            1.898736                            1.007462  \n",
      "\n",
      "[2 rows x 245 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verify the merged files were created\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# List files in the output directory\n",
    "output_files = os.listdir(output_dir)\n",
    "csv_files = [f for f in output_files if f.endswith('.csv')]\n",
    "\n",
    "print(f\"Files created in {output_dir}:\")\n",
    "for file in sorted(csv_files):\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(f\"  - {file} ({file_size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nTotal merged files created: {len(csv_files)}\")\n",
    "\n",
    "# Show a sample of one merged file\n",
    "if csv_files:\n",
    "    sample_file = os.path.join(output_dir, csv_files[0])\n",
    "    sample_df = pd.read_csv(sample_file)\n",
    "    print(f\"\\nSample of {csv_files[0]}:\")\n",
    "    print(f\"Shape: {sample_df.shape}\")\n",
    "    print(f\"Columns: {len(sample_df.columns)}\")\n",
    "    print(f\"First few column names: {list(sample_df.columns[:10])}\")\n",
    "    print(f\"First few rows:\")\n",
    "    print(sample_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "prev_pub_hash": "e4a378c2f5b6144d47f9f9e22188613f8521d0594defd52e93c38f8c51ba2243"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
