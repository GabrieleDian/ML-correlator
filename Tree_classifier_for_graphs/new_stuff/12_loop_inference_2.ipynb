{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/rezadoobary/Downloads/bayes_results_merged/20251207-013645_train_567891011_notest_vstep1/merged_looporder_20251207-013650/inference_model_sklearn.pkl\"\n",
    "feature_names = '/Users/rezadoobary/Downloads/bayes_results_merged/20251207-013645_train_567891011_notest_vstep1/merged_looporder_20251207-013650/feature_names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [9]\n",
      "6 [10]\n",
      "7 [11]\n",
      "8 [12]\n",
      "9 [13]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,10):   \n",
    "    print(i,pd.read_csv(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/{i}loops.csv\")['Basic_num_nodes'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Number of features: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/7f5zf8596_526pnhktn077f40000gn/T/ipykernel_10142/90445857.py:6: UserWarning: [16:49:07] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:82: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  model = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example\n",
    "\n",
    "\n",
    "def correct_dataset(df):\n",
    "       n = 16\n",
    "       df[\"Centrality_closeness_mean_norm\"] = df[\"Centrality_closeness_mean\"] * (n - 1)\n",
    "       df[\"Centrality_closeness_max_norm\"]  = df[\"Centrality_closeness_max\"]  * (n - 1)\n",
    "\n",
    "       # Optionally handle rows where any inputs are NaN:\n",
    "       mask =  ~np.isfinite(df[\"Centrality_closeness_mean\"]) | \\\n",
    "              ~np.isfinite(df[\"Centrality_closeness_max\"])\n",
    "\n",
    "       df.loc[mask, [\"Centrality_closeness_mean_norm\", \"Centrality_closeness_max_norm\"]] = np.nan\n",
    "       return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 119.36rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 121.37rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 114.56rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 115.98rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 115.97rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 100.82rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 97.35rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 112.39rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.18rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 99.00rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 103.53rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 86.12rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 77.28rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 52.59rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:05<00:00, 34.27rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 86.99rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:07<00:00, 25.21rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:04<00:00, 48.76rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:06<00:00, 28.80rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:00<00:00, 136.89rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19212867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]\n",
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores_vs1.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "coefficients = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    coefficients.extend(df['COEFFICIENTS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = [int(x) for x in coefficients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    coefficients,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/coefficients.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/coefficients.pkl', 'rb')\n",
    ")\n",
    "\n",
    "loop_scores = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores_vs1.pkl', 'rb')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9065544382829686"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, loop_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/rezadoobary/Downloads/bayes_results_merged/20251207-160836_train_567891011_notest_vstep12/merged_looporder_20251207-160841/inference_model_sklearn.pkl\"\n",
    "feature_names = '/Users/rezadoobary/Downloads/bayes_results_merged/20251207-160836_train_567891011_notest_vstep12/merged_looporder_20251207-160841/feature_names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Number of features: 98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:07<00:00, 27.52rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:04<00:00, 49.59rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:08<00:00, 23.80rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:09<00:00, 20.50rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:05<00:00, 35.93rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:04<00:00, 45.88rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:09<00:00, 20.63rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 51.48rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:08<00:00, 22.70rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:09<00:00, 20.33rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:05<00:00, 36.71rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:09<00:00, 22.10rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:10<00:00, 18.64rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:06<00:00, 29.26rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:08<00:00, 23.36rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:08<00:00, 22.82rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:09<00:00, 20.12rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:07<00:00, 26.65rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 57.48rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:02<00:00, 18.84rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19212867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]\n",
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores_vs12.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9059547652450028"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, scores_12loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.623746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.689544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.654997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.774524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.623746\n",
       "Recall             0.689544\n",
       "F1 Score           0.654997\n",
       "Balanced Accuracy  0.774524"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(strat_scores) > 0.29, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.662899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.698147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.805350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.662899\n",
       "Recall             0.737354\n",
       "F1 Score           0.698147\n",
       "Balanced Accuracy  0.805350"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(loop_scores) > 0.38, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quikc look at f-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_energy_DEN = 17.05997848692523\n",
      "Adjacency_energy_NUM = 6.0\n",
      "Adjacency_energy_TOTAL = 16.13930578120349\n",
      "Adjacency_energy_over_fro_DEN = 2.6324118308137825\n",
      "Adjacency_energy_over_fro_NUM = 2.4494897427831783\n",
      "Adjacency_energy_over_fro_TOTAL = 2.3295081343278796\n",
      "Adjacency_energy_per_node_DEN = 1.8955531652139141\n",
      "Adjacency_energy_per_node_NUM = 1.0\n",
      "Adjacency_energy_per_node_TOTAL = 1.793256197911499\n",
      "Adjacency_estrada_index_DEN = 122.00314220011559\n",
      "Adjacency_estrada_index_NUM = 9.258483808891462\n",
      "Adjacency_estrada_index_TOTAL = 245.58968114293356\n",
      "Adjacency_estrada_per_node_DEN = 13.555904688901732\n",
      "Adjacency_estrada_per_node_NUM = 1.5430806348152437\n",
      "Adjacency_estrada_per_node_TOTAL = 27.287742349214838\n",
      "Adjacency_moment_2_DEN = 4.666666666666667\n",
      "Adjacency_moment_2_NUM = 1.0\n",
      "Adjacency_moment_2_TOTAL = 5.333333333333333\n",
      "Adjacency_moment_2_over_avgdeg_DEN = 1.0\n",
      "Adjacency_moment_2_over_avgdeg_NUM = 1.0\n",
      "Adjacency_moment_2_over_avgdeg_TOTAL = 1.0\n",
      "Adjacency_moment_3_DEN = 9.333333333333334\n",
      "Adjacency_moment_3_NUM = 0.0\n",
      "Adjacency_moment_3_TOTAL = 15.33333333333333\n",
      "Adjacency_moment_3_over_avgdeg3_DEN = 0.09183673469387754\n",
      "Adjacency_moment_3_over_avgdeg3_NUM = 0.0\n",
      "Adjacency_moment_3_over_avgdeg3_TOTAL = 0.10107421875\n",
      "Adjacency_moment_4_DEN = 60.666666666666664\n",
      "Adjacency_moment_4_NUM = 1.0\n",
      "Adjacency_moment_4_TOTAL = 106.66666666666666\n",
      "Adjacency_moment_4_over_avgdeg4_DEN = 0.1279154518950437\n",
      "Adjacency_moment_4_over_avgdeg4_NUM = 1.0\n",
      "Adjacency_moment_4_over_avgdeg4_TOTAL = 0.13183593750000003\n",
      "Assortativity_degree_DEN = -0.4\n",
      "Assortativity_degree_TOTAL = -0.3333333333333333\n",
      "Basic_avg_degree_DEN = 4.666666666666667\n",
      "Basic_avg_degree_NUM = 1.0\n",
      "Basic_avg_degree_TOTAL = 5.333333333333333\n",
      "Basic_avg_degree_norm_DEN = 0.5833333333333334\n",
      "Basic_avg_degree_norm_NUM = 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch-env/lib/python3.10/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fgraph_features_cli3 import build_graphs_from_row, extract_features_row, parse_groups\n",
    "\n",
    "df = pd.read_csv(\"/Users/rezadoobary/Downloads/graph_data_5.csv\")\n",
    "row = df.iloc[0]\n",
    "\n",
    "groups = parse_groups(\"all\")\n",
    "\n",
    "feats = extract_features_row(\n",
    "    row,\n",
    "    groups=groups,\n",
    "    lap_eigs_k=10,\n",
    "    netlsd_points=32,\n",
    "    netlsd_tmin=0.01,\n",
    "    netlsd_tmax=100.0,\n",
    "    ind4_exact_nmax=50,\n",
    "    ind4_max_samples=50000,\n",
    "    ind5_sample_frac=1.0,\n",
    "    distance_max_sources=200,\n",
    "    distance_exact_if_leq=500,\n",
    "    seed=42,\n",
    "    intra_workers=0,\n",
    "    betweenness_k=0,\n",
    ")\n",
    "\n",
    "for k in sorted([c for c in feats.keys() if not str(feats[c]) == \"nan\"])[:40]:\n",
    "    print(k, \"=\", feats[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgraph5 = pd.read_csv(\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/fgraphs2/5_fgraph_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1   -1\n",
       "2    1\n",
       "3    1\n",
       "4   -1\n",
       "5    1\n",
       "6    1\n",
       "Name: COEFFICIENTS, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgraph5['COEFFICIENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "prev_pub_hash": "e4a378c2f5b6144d47f9f9e22188613f8521d0594defd52e93c38f8c51ba2243"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
