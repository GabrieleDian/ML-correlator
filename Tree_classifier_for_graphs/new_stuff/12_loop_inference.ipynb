{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/rezadoobary/Downloads/final_model_sklearn_10.pkl\"\n",
    "feature_names = \"/Users/rezadoobary/Downloads/feature_names_10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Number of features: 98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example\n",
    "\n",
    "\n",
    "def correct_dataset(df):\n",
    "       n = 16\n",
    "       df[\"Centrality_closeness_mean_norm\"] = df[\"Centrality_closeness_mean\"] * (n - 1)\n",
    "       df[\"Centrality_closeness_max_norm\"]  = df[\"Centrality_closeness_max\"]  * (n - 1)\n",
    "\n",
    "       # Optionally handle rows where any inputs are NaN:\n",
    "       mask =  ~np.isfinite(df[\"Centrality_closeness_mean\"]) | \\\n",
    "              ~np.isfinite(df[\"Centrality_closeness_max\"])\n",
    "\n",
    "       df.loc[mask, [\"Centrality_closeness_mean_norm\", \"Centrality_closeness_max_norm\"]] = np.nan\n",
    "       return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 69.12rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 72.21rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 69.29rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 64.40rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 67.72rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 67.98rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 66.74rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 67.98rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 64.35rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 116.78rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 67.90rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:04<00:00, 48.17rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 67.77rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 118.73rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:04<00:00, 49.98rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.01rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 66.01rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 65.45rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 67.49rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:00<00:00, 137.83rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19212867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/stratified_scores.ipynb', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/inference_model_sklearn_10.pkl\"\n",
    "feature_names = '/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/feature_names_10.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/inference_model_sklearn_10.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load modela\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load feature names\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/inference_model_sklearn_10.pkl'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.03rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.12rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:06<00:00, 31.42rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.55rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.37rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.87rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 54.63rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 93.48rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.29rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 108.73rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 106.66rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.47rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 109.29rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 64.45rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.64rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 62.20rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.10rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.26rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 108.10rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:01<00:00, 25.77rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19212867\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "coefficients = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    coefficients.extend(df['COEFFICIENTS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = [int(x) for x in coefficients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    coefficients,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/coefficients.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/coefficients.pkl', 'rb')\n",
    ")\n",
    "\n",
    "scores = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/stratified_scores.ipynb', 'rb')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876441686422635"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831892190944437"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, strat_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.623746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.689544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.654997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.774524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.623746\n",
       "Recall             0.689544\n",
       "F1 Score           0.654997\n",
       "Balanced Accuracy  0.774524"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(strat_scores) > 0.29, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.662899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.698147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.805350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.662899\n",
       "Recall             0.737354\n",
       "F1 Score           0.698147\n",
       "Balanced Accuracy  0.805350"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(loop_scores) > 0.38, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quikc look at f-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_energy_DEN = 17.05997848692523\n",
      "Adjacency_energy_NUM = 6.0\n",
      "Adjacency_energy_TOTAL = 16.13930578120349\n",
      "Adjacency_energy_over_fro_DEN = 2.6324118308137825\n",
      "Adjacency_energy_over_fro_NUM = 2.4494897427831783\n",
      "Adjacency_energy_over_fro_TOTAL = 2.3295081343278796\n",
      "Adjacency_energy_per_node_DEN = 1.8955531652139141\n",
      "Adjacency_energy_per_node_NUM = 1.0\n",
      "Adjacency_energy_per_node_TOTAL = 1.793256197911499\n",
      "Adjacency_estrada_index_DEN = 122.00314220011559\n",
      "Adjacency_estrada_index_NUM = 9.258483808891462\n",
      "Adjacency_estrada_index_TOTAL = 245.58968114293356\n",
      "Adjacency_estrada_per_node_DEN = 13.555904688901732\n",
      "Adjacency_estrada_per_node_NUM = 1.5430806348152437\n",
      "Adjacency_estrada_per_node_TOTAL = 27.287742349214838\n",
      "Adjacency_moment_2_DEN = 4.666666666666667\n",
      "Adjacency_moment_2_NUM = 1.0\n",
      "Adjacency_moment_2_TOTAL = 5.333333333333333\n",
      "Adjacency_moment_2_over_avgdeg_DEN = 1.0\n",
      "Adjacency_moment_2_over_avgdeg_NUM = 1.0\n",
      "Adjacency_moment_2_over_avgdeg_TOTAL = 1.0\n",
      "Adjacency_moment_3_DEN = 9.333333333333334\n",
      "Adjacency_moment_3_NUM = 0.0\n",
      "Adjacency_moment_3_TOTAL = 15.33333333333333\n",
      "Adjacency_moment_3_over_avgdeg3_DEN = 0.09183673469387754\n",
      "Adjacency_moment_3_over_avgdeg3_NUM = 0.0\n",
      "Adjacency_moment_3_over_avgdeg3_TOTAL = 0.10107421875\n",
      "Adjacency_moment_4_DEN = 60.666666666666664\n",
      "Adjacency_moment_4_NUM = 1.0\n",
      "Adjacency_moment_4_TOTAL = 106.66666666666666\n",
      "Adjacency_moment_4_over_avgdeg4_DEN = 0.1279154518950437\n",
      "Adjacency_moment_4_over_avgdeg4_NUM = 1.0\n",
      "Adjacency_moment_4_over_avgdeg4_TOTAL = 0.13183593750000003\n",
      "Assortativity_degree_DEN = -0.4\n",
      "Assortativity_degree_TOTAL = -0.3333333333333333\n",
      "Basic_avg_degree_DEN = 4.666666666666667\n",
      "Basic_avg_degree_NUM = 1.0\n",
      "Basic_avg_degree_TOTAL = 5.333333333333333\n",
      "Basic_avg_degree_norm_DEN = 0.5833333333333334\n",
      "Basic_avg_degree_norm_NUM = 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch-env/lib/python3.10/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fgraph_features_cli3 import build_graphs_from_row, extract_features_row, parse_groups\n",
    "\n",
    "df = pd.read_csv(\"/Users/rezadoobary/Downloads/graph_data_5.csv\")\n",
    "row = df.iloc[0]\n",
    "\n",
    "groups = parse_groups(\"all\")\n",
    "\n",
    "feats = extract_features_row(\n",
    "    row,\n",
    "    groups=groups,\n",
    "    lap_eigs_k=10,\n",
    "    netlsd_points=32,\n",
    "    netlsd_tmin=0.01,\n",
    "    netlsd_tmax=100.0,\n",
    "    ind4_exact_nmax=50,\n",
    "    ind4_max_samples=50000,\n",
    "    ind5_sample_frac=1.0,\n",
    "    distance_max_sources=200,\n",
    "    distance_exact_if_leq=500,\n",
    "    seed=42,\n",
    "    intra_workers=0,\n",
    "    betweenness_k=0,\n",
    ")\n",
    "\n",
    "for k in sorted([c for c in feats.keys() if not str(feats[c]) == \"nan\"])[:40]:\n",
    "    print(k, \"=\", feats[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgraph5 = pd.read_csv(\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/fgraphs2/5_fgraph_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1   -1\n",
       "2    1\n",
       "3    1\n",
       "4   -1\n",
       "5    1\n",
       "6    1\n",
       "Name: COEFFICIENTS, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgraph5['COEFFICIENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "prev_pub_hash": "e4a378c2f5b6144d47f9f9e22188613f8521d0594defd52e93c38f8c51ba2243"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
