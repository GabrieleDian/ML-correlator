{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/rezadoobary/Documents/MLcorr_docs/merged_stratified_20251109-085546/inference_model_sklearn.pkl\"\n",
    "feature_names = '/Users/rezadoobary/Documents/MLcorr_docs/merged_stratified_20251109-085546/feature_names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [9]\n",
      "6 [10]\n",
      "7 [11]\n",
      "8 [12]\n",
      "9 [13]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,10):   \n",
    "    print(i,pd.read_csv(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/merged/{i}loops.csv\")['Basic_num_nodes'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Number of features: 98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example\n",
    "\n",
    "\n",
    "def correct_dataset(df):\n",
    "       n = 16\n",
    "       df[\"Centrality_closeness_mean_norm\"] = df[\"Centrality_closeness_mean\"] * (n - 1)\n",
    "       df[\"Centrality_closeness_max_norm\"]  = df[\"Centrality_closeness_max\"]  * (n - 1)\n",
    "\n",
    "       # Optionally handle rows where any inputs are NaN:\n",
    "       mask =  ~np.isfinite(df[\"Centrality_closeness_mean\"]) | \\\n",
    "              ~np.isfinite(df[\"Centrality_closeness_max\"])\n",
    "\n",
    "       df.loc[mask, [\"Centrality_closeness_mean_norm\", \"Centrality_closeness_max_norm\"]] = np.nan\n",
    "       return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:10<00:00, 19.87rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:10<00:00, 18.50rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:10<00:00, 18.83rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:10<00:00, 19.00rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:10<00:00, 18.48rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:11<00:00, 17.88rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:10<00:00, 18.40rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:11<00:00, 17.98rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:11<00:00, 17.87rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:11<00:00, 17.81rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:13<00:00, 14.85rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:12<00:00, 15.66rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:14<00:00, 13.74rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:12<00:00, 15.95rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:13<00:00, 14.35rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:12<00:00, 16.15rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:13<00:00, 14.65rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:12<00:00, 16.11rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:13<00:00, 15.01rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:02<00:00, 16.78rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19212867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/stratified_scores.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/inference_model_sklearn.pkl\"\n",
    "feature_names = '/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/feature_names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Number of features: 98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.03rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.12rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:06<00:00, 31.42rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.55rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.37rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.87rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 54.63rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 93.48rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.29rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 108.73rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 106.66rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.47rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 109.29rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 64.45rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.64rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 62.20rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.10rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.26rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 108.10rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:01<00:00, 25.77rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19212867\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "coefficients = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    coefficients.extend(df['COEFFICIENTS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = [int(x) for x in coefficients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    coefficients,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/coefficients.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/coefficients.pkl', 'rb')\n",
    ")\n",
    "\n",
    "loop_scores = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores.pkl', 'rb')\n",
    ")\n",
    "\n",
    "strat_scores = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/stratified_scores.pkl', 'rb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9063961284396098"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, loop_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831892190944437"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, strat_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.623746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.689544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.654997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.774524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.623746\n",
       "Recall             0.689544\n",
       "F1 Score           0.654997\n",
       "Balanced Accuracy  0.774524"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(strat_scores) > 0.29, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.662899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.698147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.805350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.662899\n",
       "Recall             0.737354\n",
       "F1 Score           0.698147\n",
       "Balanced Accuracy  0.805350"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(loop_scores) > 0.38, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "prev_pub_hash": "e4a378c2f5b6144d47f9f9e22188613f8521d0594defd52e93c38f8c51ba2243"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
