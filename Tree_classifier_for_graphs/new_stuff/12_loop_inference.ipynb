{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/home/ec2-user/ML-correlator/Tree_classifier_for_graphs/new_stuff/bayes_results/bayes_results_merged/20251207-013645_train_567891011_notest_vstep1/merged_looporder_20251207-013650/inference_model_sklearn.pkl\"\n",
    "feature_names = '/home/ec2-user/ML-correlator/Tree_classifier_for_graphs/new_stuff/bayes_results/bayes_results_merged/20251207-013645_train_567891011_notest_vstep1/merged_looporder_20251207-013650/feature_names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Number of features: 98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example\n",
    "\n",
    "\n",
    "def correct_dataset(df):\n",
    "       n = 16\n",
    "       df[\"Centrality_closeness_mean_norm\"] = df[\"Centrality_closeness_mean\"] * (n - 1)\n",
    "       df[\"Centrality_closeness_max_norm\"]  = df[\"Centrality_closeness_max\"]  * (n - 1)\n",
    "\n",
    "       # Optionally handle rows where any inputs are NaN:\n",
    "       mask =  ~np.isfinite(df[\"Centrality_closeness_mean\"]) | \\\n",
    "              ~np.isfinite(df[\"Centrality_closeness_max\"])\n",
    "\n",
    "       df.loc[mask, [\"Centrality_closeness_mean_norm\", \"Centrality_closeness_max_norm\"]] = np.nan\n",
    "       return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/1part.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m scores_12loops = []\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,\u001b[32m21\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mpart.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     df = correct_dataset(df)\n\u001b[32m     23\u001b[39m     predictions = predict_with_progress(model, df, feature_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-correlator/lib/python3.14/site-packages/pandas/io/parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-correlator/lib/python3.14/site-packages/pandas/io/parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-correlator/lib/python3.14/site-packages/pandas/io/parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml-correlator/lib/python3.14/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/1part.parquet'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/stratified_scores.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/inference_model_sklearn.pkl\"\n",
    "feature_names = '/Users/rezadoobary/Documents/MLcorr_docs/merged_looporder_20251109-083919/feature_names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Number of features: 98\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load modela\n",
    "with open(model_file, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open(feature_names, \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(model))\n",
    "print(\"Number of features:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.03rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.12rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:06<00:00, 31.42rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.55rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.37rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 94.87rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 54.63rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:02<00:00, 93.48rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.29rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 108.73rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 106.66rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.47rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 109.29rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 64.45rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.64rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 62.20rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 110.10rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 17000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:03<00:00, 59.26rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 200/200 [00:01<00:00, 108.10rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:01<00:00, 25.77rows/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19212867\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def predict_with_progress(model, df, feature_names, batch_size=5000):\n",
    "    X = df[feature_names]\n",
    "    n = len(X)\n",
    "    preds = []\n",
    "\n",
    "    for start in tqdm(range(0, n, batch_size), desc=\"Predicting\", unit=\"rows\"):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = X.iloc[start:end]\n",
    "        batch_pred = model.predict_proba(batch)[:, 1]\n",
    "        preds.append(batch_pred)\n",
    "\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# Run with progress\n",
    "\n",
    "scores_12loops = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    df = correct_dataset(df)\n",
    "    predictions = predict_with_progress(model, df, feature_names)\n",
    "    scores_12loops.extend(predictions)\n",
    "    print(i, len(scores_12loops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_12loops = [float(x) for x in scores_12loops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    scores_12loops,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "coefficients = []\n",
    "for i in range(1,21):\n",
    "    df = pd.read_parquet(f\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/12loops/merged_data/{i}part.parquet\")\n",
    "    coefficients.extend(df['COEFFICIENTS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = [int(x) for x in coefficients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    coefficients,\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/coefficients.pkl', 'wb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/coefficients.pkl', 'rb')\n",
    ")\n",
    "\n",
    "loop_scores = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/loop_scores.pkl', 'rb')\n",
    ")\n",
    "\n",
    "strat_scores = pickle.load(\n",
    "    open('/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/results/scores/stratified_scores.pkl', 'rb')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9063961284396098"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, loop_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831892190944437"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(coefficients, strat_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.623746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.689544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.654997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.774524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.623746\n",
       "Recall             0.689544\n",
       "F1 Score           0.654997\n",
       "Balanced Accuracy  0.774524"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(strat_scores) > 0.29, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.662899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.698147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.805350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Precision          0.662899\n",
       "Recall             0.737354\n",
       "F1 Score           0.698147\n",
       "Balanced Accuracy  0.805350"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = np.array(np.array(loop_scores) > 0.38, dtype = int)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Example: y_true and y_pred already defined\n",
    "y_true = coefficients\n",
    "y_pred = vals\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Score\"]).T  # T = Transpose for column format\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quikc look at f-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_energy_DEN = 17.05997848692523\n",
      "Adjacency_energy_NUM = 6.0\n",
      "Adjacency_energy_TOTAL = 16.13930578120349\n",
      "Adjacency_energy_over_fro_DEN = 2.6324118308137825\n",
      "Adjacency_energy_over_fro_NUM = 2.4494897427831783\n",
      "Adjacency_energy_over_fro_TOTAL = 2.3295081343278796\n",
      "Adjacency_energy_per_node_DEN = 1.8955531652139141\n",
      "Adjacency_energy_per_node_NUM = 1.0\n",
      "Adjacency_energy_per_node_TOTAL = 1.793256197911499\n",
      "Adjacency_estrada_index_DEN = 122.00314220011559\n",
      "Adjacency_estrada_index_NUM = 9.258483808891462\n",
      "Adjacency_estrada_index_TOTAL = 245.58968114293356\n",
      "Adjacency_estrada_per_node_DEN = 13.555904688901732\n",
      "Adjacency_estrada_per_node_NUM = 1.5430806348152437\n",
      "Adjacency_estrada_per_node_TOTAL = 27.287742349214838\n",
      "Adjacency_moment_2_DEN = 4.666666666666667\n",
      "Adjacency_moment_2_NUM = 1.0\n",
      "Adjacency_moment_2_TOTAL = 5.333333333333333\n",
      "Adjacency_moment_2_over_avgdeg_DEN = 1.0\n",
      "Adjacency_moment_2_over_avgdeg_NUM = 1.0\n",
      "Adjacency_moment_2_over_avgdeg_TOTAL = 1.0\n",
      "Adjacency_moment_3_DEN = 9.333333333333334\n",
      "Adjacency_moment_3_NUM = 0.0\n",
      "Adjacency_moment_3_TOTAL = 15.33333333333333\n",
      "Adjacency_moment_3_over_avgdeg3_DEN = 0.09183673469387754\n",
      "Adjacency_moment_3_over_avgdeg3_NUM = 0.0\n",
      "Adjacency_moment_3_over_avgdeg3_TOTAL = 0.10107421875\n",
      "Adjacency_moment_4_DEN = 60.666666666666664\n",
      "Adjacency_moment_4_NUM = 1.0\n",
      "Adjacency_moment_4_TOTAL = 106.66666666666666\n",
      "Adjacency_moment_4_over_avgdeg4_DEN = 0.1279154518950437\n",
      "Adjacency_moment_4_over_avgdeg4_NUM = 1.0\n",
      "Adjacency_moment_4_over_avgdeg4_TOTAL = 0.13183593750000003\n",
      "Assortativity_degree_DEN = -0.4\n",
      "Assortativity_degree_TOTAL = -0.3333333333333333\n",
      "Basic_avg_degree_DEN = 4.666666666666667\n",
      "Basic_avg_degree_NUM = 1.0\n",
      "Basic_avg_degree_TOTAL = 5.333333333333333\n",
      "Basic_avg_degree_norm_DEN = 0.5833333333333334\n",
      "Basic_avg_degree_norm_NUM = 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch-env/lib/python3.10/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fgraph_features_cli3 import build_graphs_from_row, extract_features_row, parse_groups\n",
    "\n",
    "df = pd.read_csv(\"/Users/rezadoobary/Downloads/graph_data_5.csv\")\n",
    "row = df.iloc[0]\n",
    "\n",
    "groups = parse_groups(\"all\")\n",
    "\n",
    "feats = extract_features_row(\n",
    "    row,\n",
    "    groups=groups,\n",
    "    lap_eigs_k=10,\n",
    "    netlsd_points=32,\n",
    "    netlsd_tmin=0.01,\n",
    "    netlsd_tmax=100.0,\n",
    "    ind4_exact_nmax=50,\n",
    "    ind4_max_samples=50000,\n",
    "    ind5_sample_frac=1.0,\n",
    "    distance_max_sources=200,\n",
    "    distance_exact_if_leq=500,\n",
    "    seed=42,\n",
    "    intra_workers=0,\n",
    "    betweenness_k=0,\n",
    ")\n",
    "\n",
    "for k in sorted([c for c in feats.keys() if not str(feats[c]) == \"nan\"])[:40]:\n",
    "    print(k, \"=\", feats[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgraph5 = pd.read_csv(\"/Users/rezadoobary/Documents/MLCORRELATORS/ML-correlator/Tree_classifier_for_graphs/new_stuff/features/fgraphs2/5_fgraph_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1   -1\n",
       "2    1\n",
       "3    1\n",
       "4   -1\n",
       "5    1\n",
       "6    1\n",
       "Name: COEFFICIENTS, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgraph5['COEFFICIENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-correlator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "prev_pub_hash": "e4a378c2f5b6144d47f9f9e22188613f8521d0594defd52e93c38f8c51ba2243"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
