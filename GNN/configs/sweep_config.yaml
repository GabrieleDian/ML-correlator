# Simple WandB Sweep Configuration
# Good starting point for hyperparameter search
program: one_run_simple.py
method: random  # Random search is simple and effective
metric:
  name: train_loss
  goal: minimize

parameters:
  # Base config file
  config:
    value: configs/config.yaml


 # Flat names only; these map to override hooks in one_run_simple.py
  learning_rate:
    distribution: log_uniform_values
    min: 0.000001
    max: 0.01
  weight_decay:
    distribution: log_uniform_values
    min: 0.000001
    max: 0.01
  hidden_channels:
    values: [32, 64, 128, 256]
  num_layers:
    values: [2, 3, 4, 5]
  dropout:
    distribution: uniform
    min: 0.3
    max: 0.5
  scheduler_type:
    value: "none"

run_cap: 3

