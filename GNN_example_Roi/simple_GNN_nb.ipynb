{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819fe926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import  global_mean_pool\n",
    "#from graph_builder import GraphBuilder  # <-- External builder\n",
    "import pandas as pd\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_add_pool, GraphNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from torch_geometric.utils import degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8af7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphBuilder_single_edge import GraphBuilder\n",
    "from save_model_results import save_model_architecture, append_evaluation_results, evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ccbc7",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c7da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a simple GNN model. \n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels,dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.norm1 = GraphNorm(hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.norm2 = GraphNorm(hidden_channels,hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.norm3 = GraphNorm(hidden_channels)\n",
    "        self.lin = torch.nn.Linear(hidden_channels, 2)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        batch = data.batch # For multiple graphs in a batch\n",
    "        x = F.relu(self.norm1(self.conv1(x, edge_index)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.norm2(self.conv2(x, edge_index)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.norm3(self.conv3(x, edge_index)))\n",
    "        x = self.dropout(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38552f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object.\n",
    "model = SimpleGNN(in_channels=4, hidden_channels=32,dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce80f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92f9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text file with model architecture\n",
    "model_results_path = save_model_architecture(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01fc48",
   "metadata": {},
   "source": [
    "## 7-9 loop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f104b",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde06fc",
   "metadata": {},
   "source": [
    "First we read the edges and coefficients of the csv files and save them in lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642cdbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the edge and y lists from the csv files\\\n",
    "edges=[]\n",
    "y=[]\n",
    "for i in range(7,10):\n",
    "    filename = f'../Graph_Edge_Data/den_graph_data_{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    edges += df['EDGES'].tolist()\n",
    "    y += df['COEFFICIENTS'].tolist()\n",
    "edges = [ast.literal_eval(e) for e in edges]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d05b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to add eigenvector features\n",
    "from torch_geometric.transforms import AddLaplacianEigenvectorPE\n",
    "eigen_vec= AddLaplacianEigenvectorPE(k=3,attr_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc640b5",
   "metadata": {},
   "source": [
    "We need to now translate the edges into dataset forms for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46fc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data object through GraphBuilder, then add the eigenvector features\n",
    "data=[GraphBuilder(solid_edges=x,coeff=y0).build() for x,y0 in zip(edges,y)]\n",
    "data = [eigen_vec(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5822ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d4044ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f188a1",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a237ae3",
   "metadata": {},
   "source": [
    "We are interested in graph classification of 0 and 1. We add two graph convolutional layers, making sure that the message passing is extended to two neighbours, and then add graph pooling to average over the whole graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, optimizer, criterion, device, n_epochs=70):\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "    patience_counter = 0\n",
    "    patience = 3\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(batch)             # out = model(batch) handles batch.x, batch.edge_index, etc.\n",
    "            loss = criterion(out, batch.coeff) # Use batch.y (or batch.coeff if that's what your dataset uses)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        loss_list.append(total_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch)\n",
    "                _, predicted = torch.max(out, 1)\n",
    "                correct += (predicted == batch.coeff).sum().item()\n",
    "                total += batch.num_graphs  # graph-level classification\n",
    "\n",
    "        accuracy = correct / total\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss={total_loss:.4f}, Accuracy={accuracy:.4f}\")\n",
    "\n",
    "        if epoch>50: \n",
    "            if loss_list[epoch-10]-loss_list[epoch] < 0.1:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping\") \n",
    "                    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db66539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=405.1964, Accuracy=0.7116\n",
      "Epoch 2: Loss=375.9961, Accuracy=0.7450\n",
      "Epoch 3: Loss=367.9365, Accuracy=0.7418\n",
      "Epoch 4: Loss=360.9222, Accuracy=0.7547\n",
      "Epoch 5: Loss=352.1686, Accuracy=0.7701\n",
      "Epoch 6: Loss=350.6374, Accuracy=0.7636\n",
      "Epoch 7: Loss=349.0823, Accuracy=0.7656\n",
      "Epoch 8: Loss=348.1315, Accuracy=0.7681\n",
      "Epoch 9: Loss=340.2691, Accuracy=0.7778\n",
      "Epoch 10: Loss=341.5102, Accuracy=0.7662\n",
      "Epoch 11: Loss=341.9163, Accuracy=0.7694\n",
      "Epoch 12: Loss=340.0747, Accuracy=0.7701\n",
      "Epoch 13: Loss=336.3990, Accuracy=0.7739\n",
      "Epoch 14: Loss=336.3163, Accuracy=0.7759\n",
      "Epoch 15: Loss=337.9801, Accuracy=0.7669\n",
      "Epoch 16: Loss=332.8196, Accuracy=0.7816\n",
      "Epoch 17: Loss=336.2141, Accuracy=0.7592\n",
      "Epoch 18: Loss=335.0381, Accuracy=0.7836\n",
      "Epoch 19: Loss=334.2576, Accuracy=0.7778\n",
      "Epoch 20: Loss=333.5175, Accuracy=0.7714\n",
      "Epoch 21: Loss=334.1727, Accuracy=0.7784\n",
      "Epoch 22: Loss=334.3035, Accuracy=0.7791\n",
      "Epoch 23: Loss=333.5532, Accuracy=0.7669\n",
      "Epoch 24: Loss=333.1584, Accuracy=0.7778\n",
      "Epoch 25: Loss=334.1093, Accuracy=0.7771\n",
      "Epoch 26: Loss=330.4647, Accuracy=0.7771\n",
      "Epoch 27: Loss=335.0321, Accuracy=0.7791\n",
      "Epoch 28: Loss=332.4503, Accuracy=0.7784\n",
      "Epoch 29: Loss=332.1493, Accuracy=0.7771\n",
      "Epoch 30: Loss=327.9549, Accuracy=0.7778\n",
      "Epoch 31: Loss=333.4673, Accuracy=0.7694\n",
      "Epoch 32: Loss=329.0244, Accuracy=0.7759\n",
      "Epoch 33: Loss=330.6848, Accuracy=0.7893\n",
      "Epoch 34: Loss=331.3736, Accuracy=0.7778\n",
      "Epoch 35: Loss=329.8964, Accuracy=0.7726\n",
      "Epoch 36: Loss=330.6701, Accuracy=0.7771\n",
      "Epoch 37: Loss=329.9568, Accuracy=0.7765\n",
      "Epoch 38: Loss=330.9385, Accuracy=0.7759\n",
      "Epoch 39: Loss=327.5915, Accuracy=0.7630\n",
      "Epoch 40: Loss=330.8411, Accuracy=0.7861\n",
      "Epoch 41: Loss=327.6484, Accuracy=0.7771\n",
      "Epoch 42: Loss=331.8684, Accuracy=0.7829\n",
      "Epoch 43: Loss=331.1759, Accuracy=0.7803\n",
      "Epoch 44: Loss=328.1675, Accuracy=0.7823\n",
      "Epoch 45: Loss=327.9413, Accuracy=0.7771\n",
      "Epoch 46: Loss=330.0323, Accuracy=0.7714\n",
      "Epoch 47: Loss=329.5597, Accuracy=0.7778\n",
      "Epoch 48: Loss=326.0369, Accuracy=0.7784\n",
      "Epoch 49: Loss=328.5233, Accuracy=0.7752\n",
      "Epoch 50: Loss=331.9502, Accuracy=0.7579\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, optimizer, criterion, device, n_epochs)\u001b[39m\n\u001b[32m      9\u001b[39m model.train()\n\u001b[32m     10\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Human-Learning/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Human-Learning/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Human-Learning/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Human-Learning/.venv/lib/python3.12/site-packages/torch_geometric/loader/dataloader.py:20\u001b[39m, in \u001b[36mCollater.__call__\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     18\u001b[39m elem = batch[\u001b[32m0\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch.Tensor):\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Human-Learning/.venv/lib/python3.12/site-packages/torch_geometric/data/batch.py:76\u001b[39m, in \u001b[36mBatch.from_data_list\u001b[39m\u001b[34m(cls, data_list, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_data_list\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_list: List[BaseData],\n\u001b[32m     66\u001b[39m                    follow_batch: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     67\u001b[39m                    exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     68\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[33;03m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[33;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m \u001b[33;03m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     batch, slice_dict, inc_dict = \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     batch._num_graphs = \u001b[38;5;28mlen\u001b[39m(data_list)\n\u001b[32m     86\u001b[39m     batch._slice_dict = slice_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Human-Learning/.venv/lib/python3.12/site-packages/torch_geometric/data/collate.py:32\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m     29\u001b[39m     data_list = \u001b[38;5;28mlist\u001b[39m(data_list)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m != data_list[\u001b[32m0\u001b[39m].\u001b[34m__class__\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     out = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_base_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Dynamic inheritance.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     34\u001b[39m     out = \u001b[38;5;28mcls\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Human-Learning/.venv/lib/python3.12/site-packages/torch_geometric/data/batch.py:31\u001b[39m, in \u001b[36mDynamicInheritance.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     25\u001b[39m name = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_cls.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# NOTE `MetaResolver` is necessary to resolve metaclass conflict\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# problems between `DynamicInheritance` and the metaclass of\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# `base_cls`. In particular, it creates a new common metaclass\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# from the defined metaclasses.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mMetaResolver\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_cls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_model(model,train_loader,test_loader,optimizer,device='cpu',criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c53c9",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04cd27b",
   "metadata": {},
   "source": [
    "We evaluate the model on test set in terms of Accuracy, Precision, Recall and F1 score. Then we save the results in a txt file. Then we also print the same metrics for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ea331",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation =evaluate_model(model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b923f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_evaluation_results(model_results_path, evaluation, loop = [7,8,9] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_train =evaluate_model(model, train_loader, device='cpu')\n",
    "print(evaluation_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03de45",
   "metadata": {},
   "source": [
    "We observe that the metrics are similar for train  and test data, indicating that the model is not overfitting. \n",
    "We should train the model for longer to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd5007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
