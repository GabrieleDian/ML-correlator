{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819fe926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "#from graph_builder import GraphBuilder  # <-- External builder\n",
    "import pandas as pd\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_add_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from torch_geometric.utils import degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde06fc",
   "metadata": {},
   "source": [
    "First we read the edges and coefficients of the csv files and save them in lists.\n",
    "\n",
    "Here we read the files for 5 to 8 loops.\n",
    "\n",
    "We aim to use 9 and 10 loop data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642cdbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=[]\n",
    "y=[]\n",
    "for i in range(5, 9):\n",
    "    filename = f'../Graph_Edge_Data/den_graph_data_{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    edges += df['EDGES'].tolist()\n",
    "    y += df['COEFFICIENTS'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c6a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [ast.literal_eval(e) for e in edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d05b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import AddLaplacianEigenvectorPE\n",
    "eigen_vec= AddLaplacianEigenvectorPE(k=3,attr_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc640b5",
   "metadata": {},
   "source": [
    "We need to now translate the edges into dataset forms for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11248fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBuilder:\n",
    "    def __init__(self, solid_edges, coeff, node_labels=None):\n",
    "        # Auto-infer node labels if not provided\n",
    "        if node_labels is None:\n",
    "            node_labels = sorted(set(u for e in solid_edges for u in e))\n",
    "        self.node_labels = node_labels\n",
    "        self.label2idx = {label: i for i, label in enumerate(node_labels)}\n",
    "\n",
    "        self.solid_edges = solid_edges\n",
    "        self.num_nodes = len(self.node_labels)\n",
    "        self.y = torch.tensor(coeff, dtype=torch.long)  # Ensure y is a column vector\n",
    "\n",
    "    def build(self, extra_node_features=None):\n",
    "        edge_list = []\n",
    "\n",
    "        for u, v in self.solid_edges:\n",
    "            i, j = self.label2idx[u], self.label2idx[v]\n",
    "            edge_list += [[i, j], [j, i]]  # bidirectional\n",
    "\n",
    "        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "        # Basic node feature: degree\n",
    "        degree_feat = degree(edge_index[0], num_nodes=self.num_nodes).view(-1, 1)\n",
    "\n",
    "        # Combine degree with extra features if provided\n",
    "        if extra_node_features is not None:\n",
    "            assert extra_node_features.shape[0] == self.num_nodes, \\\n",
    "                \"extra_node_features must match number of nodes\"\n",
    "            x = torch.cat([degree_feat, extra_node_features], dim=1)\n",
    "        else:\n",
    "            x = degree_feat\n",
    "        return Data(x=x, edge_index=edge_index, num_nodes=self.num_nodes, coeff=self.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46fc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[GraphBuilder(solid_edges=x,coeff=y0).build() for x,y0 in zip(edges,y)]\n",
    "data = [eigen_vec(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5822ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4044ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine graph_list and y into a DataLoader where graph_list represents x and y represents y with train/test split\n",
    "train_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a237ae3",
   "metadata": {},
   "source": [
    "We are interested in graph classification of 0 and 1. We add two graph convolutional layers, making sure that the message passing is extended to two neighbours, and then add graph pooling to average over the whole graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda7dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = torch.nn.Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        batch = data.batch # For multiple graphs in a batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64814711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object using CNN class\n",
    "model = SimpleGNN(in_channels=4, hidden_channels=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6492308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cross entropy loss\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54ae0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, optimizer, criterion, device, n_epochs=20):\n",
    "    accuracy_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(batch)             # out = model(batch) handles batch.x, batch.edge_index, etc.\n",
    "            loss = criterion(out, batch.coeff) # Use batch.y (or batch.coeff if that's what your dataset uses)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        loss_list.append(total_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch)\n",
    "                _, predicted = torch.max(out, 1)\n",
    "                correct += (predicted == batch.coeff).sum().item()\n",
    "                total += batch.num_graphs  # If doing graph-level classification\n",
    "                # total += batch.y.size(0)  # If doing node-level classification\n",
    "\n",
    "        accuracy = correct / total\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss={total_loss:.4f}, Accuracy={accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db66539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=200.7166, Accuracy=0.5488\n",
      "Epoch 2: Loss=199.8406, Accuracy=0.5427\n",
      "Epoch 3: Loss=198.9995, Accuracy=0.5915\n",
      "Epoch 4: Loss=197.8695, Accuracy=0.5427\n",
      "Epoch 5: Loss=198.0695, Accuracy=0.5427\n",
      "Epoch 6: Loss=198.2646, Accuracy=0.5854\n",
      "Epoch 7: Loss=197.4068, Accuracy=0.6159\n",
      "Epoch 8: Loss=197.5364, Accuracy=0.5915\n",
      "Epoch 9: Loss=197.2759, Accuracy=0.5854\n",
      "Epoch 10: Loss=196.8274, Accuracy=0.5427\n",
      "Epoch 11: Loss=197.2086, Accuracy=0.6159\n",
      "Epoch 12: Loss=196.3848, Accuracy=0.6159\n",
      "Epoch 13: Loss=197.2735, Accuracy=0.5854\n",
      "Epoch 14: Loss=196.9252, Accuracy=0.5427\n",
      "Epoch 15: Loss=196.2797, Accuracy=0.6098\n",
      "Epoch 16: Loss=196.7048, Accuracy=0.5427\n",
      "Epoch 17: Loss=196.6874, Accuracy=0.6159\n",
      "Epoch 18: Loss=196.6030, Accuracy=0.5671\n",
      "Epoch 19: Loss=196.4089, Accuracy=0.5732\n",
      "Epoch 20: Loss=197.1290, Accuracy=0.5976\n",
      "Epoch 21: Loss=196.5935, Accuracy=0.5427\n",
      "Epoch 22: Loss=196.2088, Accuracy=0.5976\n",
      "Epoch 23: Loss=196.1308, Accuracy=0.6037\n",
      "Epoch 24: Loss=196.2427, Accuracy=0.5854\n",
      "Epoch 25: Loss=196.5165, Accuracy=0.6037\n",
      "Epoch 26: Loss=196.1254, Accuracy=0.6098\n",
      "Epoch 27: Loss=195.4676, Accuracy=0.5915\n",
      "Epoch 28: Loss=194.9888, Accuracy=0.5427\n",
      "Epoch 29: Loss=195.0113, Accuracy=0.5976\n",
      "Epoch 30: Loss=197.3180, Accuracy=0.5488\n",
      "Epoch 31: Loss=196.4219, Accuracy=0.5427\n",
      "Epoch 32: Loss=194.6298, Accuracy=0.5976\n",
      "Epoch 33: Loss=195.8638, Accuracy=0.5915\n",
      "Epoch 34: Loss=195.8698, Accuracy=0.5915\n",
      "Epoch 35: Loss=196.5444, Accuracy=0.5854\n",
      "Epoch 36: Loss=196.0440, Accuracy=0.6037\n",
      "Epoch 37: Loss=195.1997, Accuracy=0.5793\n",
      "Epoch 38: Loss=196.6417, Accuracy=0.5976\n",
      "Epoch 39: Loss=196.6615, Accuracy=0.5427\n",
      "Epoch 40: Loss=196.0826, Accuracy=0.5976\n",
      "Epoch 41: Loss=195.2375, Accuracy=0.6159\n",
      "Epoch 42: Loss=196.0461, Accuracy=0.6098\n",
      "Epoch 43: Loss=196.5052, Accuracy=0.5915\n",
      "Epoch 44: Loss=195.7172, Accuracy=0.5793\n",
      "Epoch 45: Loss=196.6188, Accuracy=0.5976\n",
      "Epoch 46: Loss=195.0398, Accuracy=0.5854\n",
      "Epoch 47: Loss=195.9726, Accuracy=0.6098\n",
      "Epoch 48: Loss=195.7989, Accuracy=0.5915\n",
      "Epoch 49: Loss=195.7187, Accuracy=0.6098\n",
      "Epoch 50: Loss=195.0859, Accuracy=0.5427\n",
      "Epoch 51: Loss=196.5007, Accuracy=0.6098\n",
      "Epoch 52: Loss=196.4129, Accuracy=0.5915\n",
      "Epoch 53: Loss=196.2059, Accuracy=0.5854\n",
      "Epoch 54: Loss=195.5045, Accuracy=0.5915\n",
      "Epoch 55: Loss=193.8732, Accuracy=0.5427\n",
      "Epoch 56: Loss=195.8181, Accuracy=0.5915\n",
      "Epoch 57: Loss=195.1788, Accuracy=0.5427\n",
      "Epoch 58: Loss=196.4795, Accuracy=0.6159\n",
      "Epoch 59: Loss=196.4764, Accuracy=0.5427\n",
      "Epoch 60: Loss=194.3398, Accuracy=0.5427\n",
      "Epoch 61: Loss=195.8470, Accuracy=0.5915\n",
      "Epoch 62: Loss=195.4236, Accuracy=0.6098\n",
      "Epoch 63: Loss=194.7468, Accuracy=0.5427\n",
      "Epoch 64: Loss=196.1110, Accuracy=0.5854\n",
      "Epoch 65: Loss=195.6922, Accuracy=0.5427\n",
      "Epoch 66: Loss=196.2203, Accuracy=0.5610\n",
      "Epoch 67: Loss=195.3805, Accuracy=0.5976\n",
      "Epoch 68: Loss=195.7107, Accuracy=0.5976\n",
      "Epoch 69: Loss=196.5050, Accuracy=0.6037\n",
      "Epoch 70: Loss=195.9825, Accuracy=0.6159\n",
      "Epoch 71: Loss=195.8553, Accuracy=0.5427\n",
      "Epoch 72: Loss=194.3670, Accuracy=0.5671\n",
      "Epoch 73: Loss=195.1199, Accuracy=0.5915\n",
      "Epoch 74: Loss=195.9753, Accuracy=0.5427\n",
      "Epoch 75: Loss=194.6836, Accuracy=0.6098\n",
      "Epoch 76: Loss=194.8763, Accuracy=0.5854\n",
      "Epoch 77: Loss=195.9621, Accuracy=0.5915\n",
      "Epoch 78: Loss=196.0482, Accuracy=0.5915\n",
      "Epoch 79: Loss=195.8083, Accuracy=0.5427\n",
      "Epoch 80: Loss=196.2586, Accuracy=0.6037\n",
      "Epoch 81: Loss=194.5469, Accuracy=0.5976\n",
      "Epoch 82: Loss=194.7884, Accuracy=0.5427\n",
      "Epoch 83: Loss=196.6334, Accuracy=0.5427\n",
      "Epoch 84: Loss=193.9711, Accuracy=0.5854\n",
      "Epoch 85: Loss=194.9689, Accuracy=0.5915\n",
      "Epoch 86: Loss=194.1248, Accuracy=0.6159\n",
      "Epoch 87: Loss=195.5170, Accuracy=0.5793\n",
      "Epoch 88: Loss=194.4578, Accuracy=0.5915\n",
      "Epoch 89: Loss=195.4234, Accuracy=0.5854\n",
      "Epoch 90: Loss=195.4031, Accuracy=0.6159\n",
      "Epoch 91: Loss=195.1730, Accuracy=0.6220\n",
      "Epoch 92: Loss=195.1093, Accuracy=0.5427\n",
      "Epoch 93: Loss=195.6832, Accuracy=0.5976\n",
      "Epoch 94: Loss=195.6382, Accuracy=0.6098\n",
      "Epoch 95: Loss=194.4418, Accuracy=0.6037\n",
      "Epoch 96: Loss=196.0837, Accuracy=0.5915\n",
      "Epoch 97: Loss=196.3831, Accuracy=0.6098\n",
      "Epoch 98: Loss=194.4097, Accuracy=0.5854\n",
      "Epoch 99: Loss=194.9686, Accuracy=0.5366\n",
      "Epoch 100: Loss=195.4449, Accuracy=0.5915\n"
     ]
    }
   ],
   "source": [
    "train_model(model,train_loader,test_loader,optimizer,n_epochs=100,device='cpu',criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ea331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
