\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Setup and Motivation}{1}{section.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of f-graph data across loops.}}{2}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:fgraph}{{1}{2}{Summary of f-graph data across loops}{table.caption.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of solid graph data across loops.}}{2}{table.caption.2}\protected@file@percent }
\newlabel{tab:solidgraph}{{2}{2}{Summary of solid graph data across loops}{table.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Random forest for f-graphs}{2}{section.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Random Forest results for loops 7 to 10 using 0.8 training set and corresponding full set accuracies.}}{3}{table.caption.3}\protected@file@percent }
\newlabel{tab:rf_loops_summary}{{3}{3}{Random Forest results for loops 7 to 10 using 0.8 training set and corresponding full set accuracies}{table.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Models and Methodology}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}8-loop result}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Logistic Regression}{4}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Decision Tree}{4}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Random Forest}{4}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Perfect Classification and Feature Importance}{5}{subsection.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Classification accuracy of different models trained on the full dataset. Random Forest achieves perfect accuracy, indicating that the coefficient labels are in principle learnable from the given features. Removing the denominator features causes a small but non-negligible drop in performance.}}{5}{table.caption.4}\protected@file@percent }
\newlabel{tab:full_dataset_results}{{4}{5}{Classification accuracy of different models trained on the full dataset. Random Forest achieves perfect accuracy, indicating that the coefficient labels are in principle learnable from the given features. Removing the denominator features causes a small but non-negligible drop in performance}{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}10-loop result}{6}{section.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Random Forest classification report. Accuracy: 0.8949. Computational time 11 min 30 sec.}}{6}{table.caption.5}\protected@file@percent }
\newlabel{tab:rf_10_loop}{{5}{6}{Random Forest classification report. Accuracy: 0.8949. Computational time 11 min 30 sec}{table.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Denominator Graph Classification}{7}{section.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Random Forest classification performance using only denominator graph features. The macro F1-score averages performance across the two classes (0 and 1).}}{7}{table.caption.7}\protected@file@percent }
\newlabel{tab:denominator_summary}{{6}{7}{Random Forest classification performance using only denominator graph features. The macro F1-score averages performance across the two classes (0 and 1)}{table.caption.7}{}}
\gdef \@abspage@last{8}
